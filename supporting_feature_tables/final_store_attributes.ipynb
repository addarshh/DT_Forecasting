{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import urllib\n",
    "import urllib3\n",
    "from census import Census\n",
    "from us import states\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###csv file we got from DT\n",
    "store_attr=pd.read_csv(\"/working/discount_tire/data/store_attributes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_attr[\"close_date\"] = np.where(store_attr['store_sales_close_date']=='9999-12-31', pd.datetime.now().strftime(\"%Y-%m-%d\"), store_attr[\"store_sales_close_date\"])\n",
    "store_attr['store_open_date']=pd.to_datetime(store_attr['store_open_date'])\n",
    "store_attr['close_date']=pd.to_datetime(store_attr['close_date'])\n",
    "store_attr['store_age'] = store_attr['close_date'] - store_attr['store_open_date']\n",
    "store_attr['store_age'] = store_attr['store_age'] /  np.timedelta64(1, 'Y')\n",
    "del store_attr['close_date']\n",
    "#store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### getting distance from closest store in km \n",
    "def haversine_np(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "\n",
    "    All args must be of equal length.    \n",
    "\n",
    "    \"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km = 6367 * c\n",
    "    return km\n",
    "\n",
    "data_new = store_attr[['store_code','store_latitude_degree', 'store_longitude_degree']].drop_duplicates()\n",
    "data_new['key'] = 1\n",
    "final_data = data_new.merge(data_new, how = 'left', on = ['key'])\n",
    "final_data['distance_in_km'] = haversine_np(final_data['store_longitude_degree_x'],final_data['store_latitude_degree_x'],final_data['store_longitude_degree_y'],final_data['store_latitude_degree_y'])\n",
    "\n",
    "final_data=final_data[final_data['store_code_x']!=final_data['store_code_y']]\n",
    "final_data=final_data.groupby('store_code_x')['distance_in_km'].min()\n",
    "final_data=pd.DataFrame(final_data)\n",
    "final_data=final_data.reset_index()\n",
    "final_data.rename(columns={'store_code_x':'store_code','distance_in_km':'distance_to_nearest_store_km'}, inplace=True)\n",
    "store_attr=pd.merge(store_attr,final_data, on=['store_code'], how='left')\n",
    "#store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historical weather info for all the stores\n",
    "# This file is generated from hive based on 30 years of data\n",
    "store_hist_weather_info=pd.read_csv(\"/working/discount_tire/faisal/feature_addition/store_hist_weather_info.csv\")\n",
    "store_hist_weather_info = store_hist_weather_info.drop(store_hist_weather_info.columns[[0]], axis=1)\n",
    "store_hist_weather_info=store_hist_weather_info[['store_code','avg_temp','avg_pcp','avg_acc_snow','max_temp','max_pcp','max_acc_snow',\n",
    "                                                 'min_temp','min_pcp','min_acc_snow','stddev_temp','stddev_pcp','stddev_acc_snow']]\n",
    "store_attr=pd.merge(store_attr, store_hist_weather_info, on=['store_code'], how='left')\n",
    "#store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional_store_characterstics\n",
    "## This file is from DT\n",
    "lot_and_building_characteristics=pd.read_csv(\"/working/discount_tire/faisal/feature_addition/lot_and_building_characteristics.csv\")\n",
    "lot_and_building_characteristics.rename(columns={'Store ID': 'store_code','Building Size (SF)':'building_size_sqft','Land Size (SF)':'land_size_sqft','# of Bays':'no_of_bays','# of Parking Stalls':'no_of_parking_stalls','Shared Parking':'shared_parking','Store Format':'store_format'}, inplace=True)\n",
    "lot_and_building_characteristics=lot_and_building_characteristics[[\"store_code\",\"building_size_sqft\",\"land_size_sqft\",\"no_of_bays\",\"no_of_parking_stalls\"]]\n",
    "lot_and_building_characteristics['no_of_parking_stalls'] = np.where(lot_and_building_characteristics['no_of_parking_stalls'] =='40+', 45, lot_and_building_characteristics['no_of_parking_stalls'])\n",
    "\n",
    "store_attr=pd.merge(store_attr, lot_and_building_characteristics, on=['store_code'], how='left')\n",
    "#store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supporting functions to request json response from API and create the elevation column\n",
    "def make_remote_request(url: str, params: dict):\n",
    "    \"\"\"\n",
    "    Makes the remote request\n",
    "    Continues making attempts until it succeeds\n",
    "    \"\"\"\n",
    "\n",
    "    count = 1\n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.get((url + urllib.parse.urlencode(params)))\n",
    "        except (OSError, urllib3.exceptions.ProtocolError) as error:\n",
    "            print('\\n')\n",
    "            print('*' * 20, 'Error Occured', '*' * 20)\n",
    "            print('Number of tries:{}'.format(count))\n",
    "            print('URL: {}'.format(url))\n",
    "            print(error)\n",
    "            print('\\n')\n",
    "            count += 1\n",
    "            continue\n",
    "        break\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def elevation_function(x):\n",
    "    url = 'https://nationalmap.gov/epqs/pqs.php?'\n",
    "    params = {'x': x['store_longitude_degree'],\n",
    "              'y': x['store_latitude_degree'],\n",
    "              'units': 'Meters',\n",
    "              'output': 'json'}\n",
    "    result = make_remote_request(url, params)\n",
    "    return result.json()['USGS_Elevation_Point_Query_Service']['Elevation_Query']['Elevation']\n",
    "\n",
    "\n",
    "store_attr['elevation_meter'] = store_attr.apply(elevation_function, axis=1)\n",
    "#store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####key set up steps\n",
    "'''\n",
    "Step 1 - Go to https://www.census.gov/data/developers/guidance/api-user-guide.html\n",
    "\n",
    "Step 2 - Click on \"Request a Key\"\n",
    "\n",
    "Step 3 - Enter your organisation name and email address \n",
    "\n",
    "Step 4 - You will receive the API Key in email provided.\n",
    "\n",
    "'''\n",
    "\n",
    "####Details\n",
    "'''\n",
    "Data source: api.census.gov (American Community Survey – 2018) ​\n",
    "\n",
    "Information available at zip code level – mapped store to corresponding zip code​\n",
    "\n",
    "'census' Package used to call values from the API​\n",
    "\n",
    "Added Features on zip code level: ​\n",
    "\n",
    "Population/male population/female population​\n",
    "\n",
    "Aggregate number of vehicles (cars, trucks or vans)​\n",
    "\n",
    "median income in dollars​\n",
    "\n",
    "No. of housing units ​\n",
    "\n",
    "Individuals owning 0/1/2/3/4/5 or more number of vehicles​\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'f34e78b85a544c493c9dcdfe4c00a893238052fa' #unique key required for API call  To do link to doc to have more understanding\n",
    "c = Census(key) \n",
    "\n",
    "def add_features(df):\n",
    "    \n",
    "    def func(pin, code, dummy):\n",
    "        pin = pin.split('-')[0]\n",
    "        try:\n",
    "            v = c.acs5.zipcode(code, pin)[0][code]\n",
    "            return v\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    \n",
    "    df['total_population'] = df['store_postal_code'].apply(func, args=('B01001_002E',None))\n",
    "    \n",
    "    df['male_population'] = df['store_postal_code'].apply(func, args=('B01001_001E',None))\n",
    "\n",
    "    df['female_population'] = df['store_postal_code'].apply(func, args=('B01001_002E',None))\n",
    "\n",
    "    df['housing_unit'] = df['store_postal_code'].apply(func, args=('B25001_001E',None))\n",
    "    \n",
    "    df['aggregate_vehicles'] = df['store_postal_code'].apply(func, args=('B08015_001E',None))\n",
    "    \n",
    "    df['median income'] = df['store_postal_code'].apply(func, args=('B06011_001E',None))   # median income\n",
    "    \n",
    "    df['individuals_with_no_vehicle'] = df['store_postal_code'].apply(func, args=('B08014_002E',None))  # individuals with no vehicle\n",
    "\n",
    "    df['individuals_with_one_vehicle'] = df['store_postal_code'].apply(func, args=('B08014_003E',None))  # individuals with 1 vehicle\n",
    "\n",
    "    df['individuals_with_two_vehicle'] = df['store_postal_code'].apply(func, args=('B08014_004E',None))  # individuals with 2 vehicles\n",
    "\n",
    "    df['individuals_with_three_vehicle'] = df['store_postal_code'].apply(func, args=('B08014_005E',None))  # individuals with 3 vehicles\n",
    "\n",
    "    df['individuals_with_four_vehicle'] = df['store_postal_code'].apply(func, args=('B08014_006E',None))  # individuals with 4 vehicles\n",
    "\n",
    "    df['individuals_with_five_or_more_vehicle'] = df['store_postal_code'].apply(func, args=('B08014_007E',None))  # individuals with 5 or more vehicles\n",
    "\n",
    "    df['individuals_total'] = df['store_postal_code'].apply(func, args=('B08014_001E',None))  # Total vehicles data available\n",
    "\n",
    "    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_dataframe(df, function):\n",
    "    n_cores=(multiprocessing.cpu_count()) - 8\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(function, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=store_attr[['store_code','store_postal_code']]\n",
    "#df=df.head(5)\n",
    "start = time.time()\n",
    "final_census = parallelize_dataframe(df, add_features)\n",
    "print(time.time()-start)\n",
    "#final_census\n",
    "del final_census['store_postal_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_attr=pd.merge(store_attr, final_census, on=['store_code'], how='left')\n",
    "#store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_attr.to_csv('final_store_attributes.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
